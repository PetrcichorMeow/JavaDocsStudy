# 项目总结

## 1 项目简介

​	项目分为前端,后端，算法端，三个端我都有参与，主要负责的是后端相关的工作。项目的数据来源于上海市松江区12345热线电话，每一条数据其实就是市民的一个反馈投诉，也就是一条案件，主要反映的就是市民日常生活中遇到的各类问题及困难，比如噪音扰民，消防安全隐患，医疗纠纷，教育工作等。我们就通过一些智能算法+数据分析等手段去帮助他们电话热线的业务人员提高工作效率，减轻工作压力。

## 2 模块

### 2.1 智能派单

​	问题的来源每一条案件都是需要一个具体的部门去处理的，比如教育问题就得教育处理，公共安全就得公安局处理这种，不过由于部分市民在进行热线反馈的时候提供的问题描述不够精确或者地址不够精准，市民说个几句话就不说了，业务人员不能够精确的将案件指派到对应的主责部门去处理，导致会出现错误派单的问题，一来二回，市民的问题就难以在短时间内得到解决，甲方的核心诉求就是让我们提高这个派单的准确率。

​	我们拿到数据之后，我们拿到的数据量大概在200万左右，对于我们比较有用的字段就是问题描述和地址两个字段，问题描述通常是长的长，短的短，导致最后分类出来的效果不太好，这一类问题我们称为短文本分类问题。我们用的是Word2Vec+TextCNN模型，进行词向量化之后，接TextCNN进行训练，然后再接一个SoftMax，分类出来一个78维的向量，代表的就是对应到这个主责部门的概率，因为一共有78个主责部门，但是我们发现这种分类出来的效果不是特别好，后面我们就再加了一个子网络，我们把案发地址也加入了进来，最后接一个全连接层再接SoftMax，这样我们的准确率一下就提高了，我们用历史数据测出来的准确率在93%，然后甲方用现场一个月的数据测了，准确率在89%，这个准确率肯定是会随着数据量的增多越变越高的，我们一般取前三进行推荐，能够极大的减轻他们业务人员的压力。

### 2.2 报表报告

​	主表是他们那边给我们的，有130多个字段，不过常用的就三四十个字段吧。但是他们一张报表要查的字段是42个字段，就全部得从这张表以及其他表联合查询出来生成报表。因为涉及到还有一些排名字段，我刚开始写了一条1300行的SQL，就是大量的left join，加对应字段的计算，有些字段是关联的，比如分子，分母和对应的百分比，整体下来的业务逻辑不算困难，但是是特别繁琐的，这样我们查一个半年的报表大概在50s左右，后面就开始优化。我们就将每个字段的计算全部拆分开来，在一个字段的计算中将他的分子分母百分比都算出来，然后再JAVA后台通过主责部门这个字段进行合并。我们刚刚说了需要分类为三个类别，所以这里我们用了多线程去查，就用了三个线程，再用了countDownLatch，等到三个类别的数据都都查询完毕之后再进行合并，当然还有SQL的一些优化，编写的一些逻辑已经语法的优化，比如小表驱动大表，多用了一些case when等等，这样优化下来查询半年的数据只需要7，8秒。

​	报告的话就是用的Freemaker这个模板引擎进行的渲染。

### 2.3 热词

​	就是他们想要去知道每个街镇，每个主责部门，或者是某一个案件类型下市民投诉的关键热词有哪些。然后我们就用了JieBa分词给他们做了一个词云图，编写联合查询语句，查询出对应的一个数据，对语料进行预处理，如去停词、中文常用字、过滤广告文本等，比如嗯，哦，好的这种词汇，然后用Jieba分词进行分词，这里后续为了提高速度，我们采取了一个Fast_Jieba的库，大概是jieba分词的两倍速度。我们然后再去计算他的一个热度，我们是通过两方面来计算一个词的热度的，一个就是词频，比如这个词今天出现了1000词，1000就是他的词频根据词频大小进行排序，第二个就是比值，就是当天出现词频占历史总词频的一个比值，这个比值越大说明热度越高，我们采取了贝叶斯平均的方式来修正两部分的一个分数计算，通过取得分前30的词汇进行热词展示。

### 2.4 其他

我还负责的部分比如大屏展示，回访分析，阈值管理，热点检索这些功能。

## 3 技术

```
SpringBoot
GRPC
Solr
Python相关库
org.apache.poi
```

## 4 项目难点

需求不定，需求变动特别快。

甲方总是天马星空，时间周期要得特别急，很多时候周五发需求，周一要。

